{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c842cec4",
   "metadata": {},
   "source": [
    "# This notebook is responsible for downloading and preparing datasets from various source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16127b1",
   "metadata": {},
   "source": [
    "---> 5 videos from Google Drive (which will be split into frames)  \n",
    "---> dataset from roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdfaa9",
   "metadata": {},
   "source": [
    "## Defininig path of the project and the paths where the train/valid/test sets will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb302fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Path of the project\n",
    "PROJECT_PATH = Path(os.getcwd()).resolve().parent\n",
    "\n",
    "# Main data dir\n",
    "DATA_PATH = PROJECT_PATH / 'data'\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Paths to train, valid and test dir\n",
    "TRAIN_PATH = DATA_PATH / 'train'\n",
    "TRAIN_IMAGES_PATH = TRAIN_PATH / 'images'\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TRAIN_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "VALID_PATH = DATA_PATH / 'valid'\n",
    "VALID_IMAGES_PATH = VALID_PATH / 'images'\n",
    "os.makedirs(VALID_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "TEST_PATH = DATA_PATH / 'test'\n",
    "TEST_IMAGES_PATH = TEST_PATH / 'images'\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Path to origin videos dir\n",
    "ORIGIN_VIDEOS_PATH = DATA_PATH / 'origin_videos'\n",
    "os.makedirs(ORIGIN_VIDEOS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069e3f2",
   "metadata": {},
   "source": [
    "## Preparing videos from Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888609b",
   "metadata": {},
   "source": [
    "### Download videos from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66baf4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\n",
      "To: /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/origin_videos/0bfacc_0.mp4\n",
      "100%|██████████████████████████████████████| 19.9M/19.9M [00:01<00:00, 11.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\n",
      "To: /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/origin_videos/2e57b9_0.mp4\n",
      "100%|██████████████████████████████████████| 21.1M/21.1M [00:02<00:00, 10.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\n",
      "To: /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/origin_videos/08fd33_0.mp4\n",
      "100%|██████████████████████████████████████| 19.9M/19.9M [00:01<00:00, 11.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\n",
      "To: /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/origin_videos/573e61_0.mp4\n",
      "100%|██████████████████████████████████████| 18.9M/18.9M [00:01<00:00, 11.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\n",
      "To: /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/origin_videos/121364_0.mp4\n",
      "100%|██████████████████████████████████████| 17.2M/17.2M [00:01<00:00, 11.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/0bfacc_0.mp4\" \"https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/2e57b9_0.mp4\" \"https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/08fd33_0.mp4\" \"https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/573e61_0.mp4\" \"https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/121364_0.mp4\" \"https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4015682",
   "metadata": {},
   "source": [
    "### Extracting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca043a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import supervision as sv\n",
    "import cv2\n",
    "\n",
    "def extract_frames(video_path: Path, output_path: Path, stride=5):\n",
    "    \"\"\"\n",
    "    Extracts frames from the provided video and saves them as .jpg files with unique indexes\n",
    "    (e.g. <video_name>_<frame_idx>.jpg), starting from a given index and at a specific frequency (stride).\n",
    "\n",
    "    Args:\n",
    "        video_path (Path): Path to the video file which frames will be extracted.\n",
    "        output_path (Path): Path to the output directory where the frames will be saved.\n",
    "        stride (int): The frequency of frame extraction. For example, if stride=5, every 5th frame will be extracted. Defaults to 5.\n",
    "    \"\"\"\n",
    "\n",
    "    # Video information\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "    # Frames generator\n",
    "    frame_generator = sv.get_video_frames_generator(video_path, stride=stride)\n",
    "\n",
    "    current_video = video_path.stem\n",
    "    frame_idx = 0\n",
    "    for frame in tqdm(frame_generator, desc=f'Extracting frames from video -> {current_video}', total=int(video_info.total_frames / stride)):\n",
    "        output_frame_path = output_path / f'{current_video}_{frame_idx}.jpg'\n",
    "        cv2.imwrite(output_frame_path, frame)\n",
    "\n",
    "        frame_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e63ac384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frames from video -> 121364_0: 100%|██████████| 150/150 [00:02<00:00, 53.18it/s]\n",
      "Extracting frames from video -> 0bfacc_0: 100%|██████████| 150/150 [00:02<00:00, 54.23it/s]\n",
      "Extracting frames from video -> 08fd33_0: 100%|██████████| 150/150 [00:02<00:00, 67.65it/s]\n",
      "Extracting frames from video -> 2e57b9_0: 100%|██████████| 150/150 [00:02<00:00, 51.12it/s]\n",
      "Extracting frames from video -> 573e61_0: 100%|██████████| 150/150 [00:02<00:00, 67.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 images from videos were saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dir where the extracted frames will be saved\n",
    "EXTRACTED_FRAMES_PATH = DATA_PATH / 'extracted_frames'\n",
    "os.makedirs(EXTRACTED_FRAMES_PATH, exist_ok=True)\n",
    "\n",
    "STRIDE = 5\n",
    "\n",
    "# Process each video in ORIGIN_VIDEOS_PATH directory\n",
    "for video_file_name in os.listdir(ORIGIN_VIDEOS_PATH):\n",
    "    video_path = ORIGIN_VIDEOS_PATH / video_file_name\n",
    "    extract_frames(video_path, EXTRACTED_FRAMES_PATH, stride=STRIDE)\n",
    "\n",
    "print(f'{len(os.listdir(EXTRACTED_FRAMES_PATH))} images from videos were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e549a0fb",
   "metadata": {},
   "source": [
    "### Splitting data into train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ef8accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08fd33_0: 150 images\n",
      "0bfacc_0: 150 images\n",
      "121364_0: 150 images\n",
      "2e57b9_0: 150 images\n",
      "573e61_0: 150 images\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_names = sorted(os.listdir(EXTRACTED_FRAMES_PATH))\n",
    "np_file_names = np.array(file_names)\n",
    "video_names = np.array(['_'.join(file_name.split('_')[:-1]) for file_name in file_names])\n",
    "unique, counts = np.unique(video_names, return_counts=True)\n",
    "\n",
    "for video_name, count in zip(unique, counts):\n",
    "    print(f'{video_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "83d62f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VALID_SIZE = 0.1\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "train_full_images, valid_images, train_full_mask, valid_mask = train_test_split(np_file_names, video_names, test_size=TEST_SIZE, stratify=video_names)\n",
    "train_images, test_images, train_mask, test_mask = train_test_split(train_full_images, train_full_mask, test_size=TEST_SIZE, stratify=train_full_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40f52c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Video 08fd33_0: 122 images\n",
      "Video 0bfacc_0: 121 images\n",
      "Video 121364_0: 121 images\n",
      "Video 2e57b9_0: 122 images\n",
      "Video 573e61_0: 121 images\n",
      "Total Train Images: 607\n",
      "\n",
      "Valid Set\n",
      "Video 08fd33_0: 15 images\n",
      "Video 0bfacc_0: 15 images\n",
      "Video 121364_0: 15 images\n",
      "Video 2e57b9_0: 15 images\n",
      "Video 573e61_0: 15 images\n",
      "Total Valid Images: 75\n",
      "\n",
      "Test Set\n",
      "Video 08fd33_0: 13 images\n",
      "Video 0bfacc_0: 14 images\n",
      "Video 121364_0: 14 images\n",
      "Video 2e57b9_0: 13 images\n",
      "Video 573e61_0: 14 images\n",
      "Total Test Images: 68\n"
     ]
    }
   ],
   "source": [
    "print('Train Set')\n",
    "video_ids, train_counts = np.unique(train_mask, return_counts=True)\n",
    "for n_video, count in zip(video_ids, train_counts):\n",
    "    print(f'Video {n_video}: {count} images')\n",
    "print(f'Total Train Images: {len(train_mask)}')\n",
    "\n",
    "print('\\nValid Set')\n",
    "video_ids, valid_counts = np.unique(valid_mask, return_counts=True)\n",
    "for n_video, count in zip(video_ids, valid_counts):\n",
    "    print(f'Video {n_video}: {count} images')\n",
    "print(f'Total Valid Images: {len(valid_mask)}')\n",
    "\n",
    "print('\\nTest Set')\n",
    "video_ids, test_counts = np.unique(test_mask, return_counts=True)\n",
    "for n_video, count in zip(video_ids, test_counts):\n",
    "    print(f'Video {n_video}: {count} images')\n",
    "print(f'Total Test Images: {len(test_mask)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed396ae",
   "metadata": {},
   "source": [
    "### Moving the train, valid and test set to the appropriate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c80480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def move_images(image_paths_list: list[Path], target_folder_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Moves images from the current folder to the target folder. It checks if the image files \n",
    "    have a \".jpg\" extension and then moves them to the specified target folder.\n",
    "\n",
    "    Args:\n",
    "        image_paths_list (list[Path]): A list of 'Path' objects, where each path refers to an image file \n",
    "                                       that should be moved. The images should be in `.jpg` format.\n",
    "        target_folder_path (Path): The 'Path' object representing the target folder where the images \n",
    "                                    will be moved. The target folder should already exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through each image path in the list\n",
    "    for image_path in tqdm(image_paths_list, desc=f'Transferring images to {target_folder_path}', total=len(image_paths_list)):\n",
    "        # Check if the file is in the appropriate format '.jpg'\n",
    "        if str(image_path).endswith('.jpg'):\n",
    "            # Absolute path for the output image\n",
    "            output_image_path = target_folder_path / image_path.name\n",
    "\n",
    "            # Move the image from the source to the target foler\n",
    "            shutil.move(image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1801e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transferring images to /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/train/images: 100%|██████████| 607/607 [00:00<00:00, 15961.62it/s]\n",
      "Transferring images to /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/valid/images: 100%|██████████| 75/75 [00:00<00:00, 18411.14it/s]\n",
      "Transferring images to /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/test/images: 100%|██████████| 68/68 [00:00<00:00, 14706.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create image sets (paths to each image)\n",
    "image_sets = [\n",
    "    [EXTRACTED_FRAMES_PATH / train_image for train_image in train_images],  # Train set\n",
    "    [EXTRACTED_FRAMES_PATH / valid_image for valid_image in valid_images],  # Valid set\n",
    "    [EXTRACTED_FRAMES_PATH / test_image for test_image in test_images]      # Test set\n",
    "]\n",
    "target_folder_sets = [TRAIN_IMAGES_PATH, VALID_IMAGES_PATH, TEST_IMAGES_PATH]  # List of paths for the corresponding sets\n",
    "\n",
    "# Iterate through set of images and corresponding target folder\n",
    "for image_set, target_folder_set in zip(image_sets, target_folder_sets):\n",
    "    move_images(image_paths_list=image_set, target_folder_path=target_folder_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee707129",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(EXTRACTED_FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d60a5b",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd89ea9",
   "metadata": {},
   "source": [
    "## Preparing datasets from Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b86a3",
   "metadata": {},
   "source": [
    "### Download roboflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf2ac0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in football-ai-vision-1 to coco:: 100%|██████████| 83381/83381 [00:08<00:00, 10071.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to football-ai-vision-1 in coco:: 100%|██████████| 380/380 [00:00<00:00, 1351.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Load .env file\n",
    "dotenv_path = PROJECT_PATH / '.env'\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get the Roboflow API Key\n",
    "ROBOFLOW_API_KEY = os.getenv('ROBOFLOW_API_KEY')\n",
    "\n",
    "# Change the current dir to the data directory\n",
    "HOME = Path(os.getcwd())\n",
    "os.chdir(DATA_PATH)\n",
    "\n",
    "# Download dataset\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(\"mikoaj-bu1z8\").project(\"football-ai-vision\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco\")\n",
    "\n",
    "# Return to the Home direcotry\n",
    "os.chdir(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20a2b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transferring images to /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/train/images: 100%|██████████| 299/299 [00:00<00:00, 18191.66it/s]\n",
      "Transferring images to /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/valid/images: 100%|██████████| 50/50 [00:00<00:00, 18958.16it/s]\n",
      "Transferring images to /home/mikolaj/Desktop/Projects/my_projects/football-ai/data/test/images: 100%|██████████| 26/26 [00:00<00:00, 15052.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create image sets (paths to each image)\n",
    "image_sets = [\n",
    "    [Path(dataset.location) / 'train' / train_image for train_image in os.listdir(Path(dataset.location) / 'train')],  # Train set\n",
    "    [Path(dataset.location) / 'valid' / valid_image for valid_image in os.listdir(Path(dataset.location) / 'valid')],  # Valid set\n",
    "    [Path(dataset.location) / 'test' / test_image for test_image in os.listdir(Path(dataset.location) / 'test')]       # Test set\n",
    "]\n",
    "target_folder_sets = [TRAIN_IMAGES_PATH, VALID_IMAGES_PATH, TEST_IMAGES_PATH]  # List of paths for the corresponding sets\n",
    "\n",
    "# Iterate through set of images and corresponding target folder\n",
    "for image_set, target_folder_set in zip(image_sets, target_folder_sets):\n",
    "    move_images(image_paths_list=image_set, target_folder_path=target_folder_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9249a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--data\n",
      "|  |--train\n",
      "|  |   |--images (905 images)\n",
      "|  |--valid\n",
      "|  |   |--images (124 images)\n",
      "|  |--test\n",
      "|  |   |--images  (93 iamges)\n",
      "|  |   \n",
      "|  |--origin_videos (5 videos)\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "n_train_images = len(os.listdir(TRAIN_IMAGES_PATH))\n",
    "n_valid_images = len(os.listdir(VALID_IMAGES_PATH))\n",
    "n_test_images = len(os.listdir(TEST_IMAGES_PATH))\n",
    "n_videos = len(os.listdir(ORIGIN_VIDEOS_PATH))\n",
    "\n",
    "print(f'|--data')\n",
    "print(f'|  |--train')\n",
    "print(f'|  |   |--images ({n_train_images} images)')\n",
    "print(f'|  |--valid')\n",
    "print(f'|  |   |--images ({n_valid_images} images)')\n",
    "print(f'|  |--test')\n",
    "print(f'|  |   |--images  ({n_test_images} iamges)')\n",
    "print(f'|  |   ')\n",
    "print(f'|  |--origin_videos ({n_videos} videos)')\n",
    "print(f'|')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
